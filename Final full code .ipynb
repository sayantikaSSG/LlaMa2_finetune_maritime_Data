{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:19:14.995639Z","iopub.execute_input":"2025-07-04T10:19:14.995992Z","iopub.status.idle":"2025-07-04T10:19:15.594085Z","shell.execute_reply.started":"2025-07-04T10:19:14.995974Z","shell.execute_reply":"2025-07-04T10:19:15.593447Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport requests\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\nimport re\n\n# Constants\nBASE_URL = \"https://www.emsa.europa.eu/publications.html\"\nDOWNLOAD_PREFIX = \"/publications/download\"\nOUTPUT_DIR = \"data/emsa_texts\"\nHEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\nVERIFY_SSL = False\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\ndef sanitize_filename(name):\n    return re.sub(r\"[\\\\/*?\\\"<>|]\", \"_\", name)[:80]\n\ndef find_html_pages():\n    print(\"üîç Scraping EMSA index for publication links...\")\n    try:\n        res = requests.get(BASE_URL, headers=HEADERS, verify=VERIFY_SSL)\n        res.raise_for_status()\n    except Exception as e:\n        print(f\"‚ùå Failed to load index page: {e}\")\n        return []\n\n    soup = BeautifulSoup(res.content, \"html.parser\")\n    links = []\n\n    for a in soup.find_all(\"a\", href=True):\n        href = a[\"href\"]\n        if href.startswith(DOWNLOAD_PREFIX) and href.endswith(\".html\"):\n            full_url = urljoin(BASE_URL, href)\n            title = sanitize_filename(a.get_text(strip=True) or \"EMSA_Document\")\n            links.append((full_url, title))\n\n    return links\n\ndef extract_and_save_text(url, title, index):\n    filename = f\"{index:03d}_{title}.txt\"\n    path = os.path.join(OUTPUT_DIR, filename)\n\n    if os.path.exists(path):\n        print(f\"‚úÖ Already extracted: {filename}\")\n        return\n\n    try:\n        print(f\"üìù Extracting: {filename}\")\n        res = requests.get(url, headers=HEADERS, verify=VERIFY_SSL)\n        res.raise_for_status()\n        soup = BeautifulSoup(res.content, \"html.parser\")\n\n        # Extract text from all relevant tags\n        content = []\n        for tag in soup.find_all(['h1', 'h2', 'h3', 'p', 'li']):\n            text = tag.get_text(strip=True)\n            if text:\n                content.append(text)\n\n        full_text = \"\\n\".join(content)\n\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            f.write(full_text)\n\n    except Exception as e:\n        print(f\"‚ùå Failed to extract from {url}: {e}\")\n\ndef main():\n    pages = find_html_pages()\n    print(f\"\\nüîó Found {len(pages)} document-like HTML pages.\\n\")\n\n    for i, (url, title) in enumerate(pages):\n        extract_and_save_text(url, title, i)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:19:15.595561Z","iopub.execute_input":"2025-07-04T10:19:15.595955Z","iopub.status.idle":"2025-07-04T10:31:25.801808Z","shell.execute_reply.started":"2025-07-04T10:19:15.595929Z","shell.execute_reply":"2025-07-04T10:31:25.801015Z"}},"outputs":[{"name":"stdout","text":"üîç Scraping EMSA index for publication links...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîó Found 33 document-like HTML pages.\n\nüìù Extracting: 000_EMSA Catalogue 2025 v26.06.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 001_EMSA CAAR2024.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 002_EMSA_FACTS_FIGURES_2024.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 003_Seafarers Statistics in the EU 2023 data report.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 004_AFVs Guidance 1.2 2025.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 005_ADER 2024.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 006_emsa ipa-enp newsletter issue 2.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 007_EMTER_F&F_2025_EN.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 008_EMTER_F&F_2025_BG.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 009_EMTER_F&F_2025_CS.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 010_EMTER_F&F_2025_DA.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 011_EMTER_F&F_2025_DE.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 012_EMTER_F&F_2025_EL.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 013_EMTER_F&F_2025_ES.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 014_EMTER_F&F_2025_ET.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 015_EMTER_F&F_2025_FI.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 016_EMTER_F&F_2025_FR.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 017_EMTER_F&F_2025_GA.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 018_EMTER_F&F_2025_HR.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 019_EMTER_F&F_2025_HU.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 020_EMTER_F&F_2025_IT.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 021_EMTER_F&F_2025_LT.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 022_EMTER_F&F_2025_LV.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 023_EMTER_F&F_2025_MT.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 024_EMTER_F&F_2025_NL.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 025_EMTER_F&F_2025_PL.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 026_EMTER_F&F_2025_PT.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 027_EMTER_F&F_2025_RO.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 028_EMTER_F&F_2025_SK.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 029_EMTER_F&F_2025_SL.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 030_EMTER_F&F_2025_SV.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 031_European Maritime Transport Environmental Report 2025.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"üìù Extracting: 032_EMSA Outlook 2025_v3.0.pdf.txt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.emsa.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport re\n\nINPUT_DIR = \"data/emsa_texts\"\nOUTPUT_DIR = \"data/emsa_cleaned\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\ndef clean_text(text):\n    # Basic cleaning: remove multiple line breaks, weird whitespace, control characters\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"[\\x00-\\x1f\\x7f-\\x9f]\", \"\", text)\n    return text.strip()\n\ndef process_file(path):\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        raw_text = f.read()\n    return clean_text(raw_text)\n\ndef process_all_files():\n    files = [f for f in os.listdir(INPUT_DIR) if f.endswith(\".txt\")]\n    print(f\"üßπ Cleaning {len(files)} files...\")\n\n    for f in files:\n        raw_path = os.path.join(INPUT_DIR, f)\n        clean_path = os.path.join(OUTPUT_DIR, f.replace(\".txt\", \"_cleaned.txt\"))\n\n        cleaned = process_file(raw_path)\n\n        with open(clean_path, \"w\", encoding=\"utf-8\") as out:\n            out.write(cleaned)\n\n        print(f\"‚úÖ Cleaned: {f}\")\n\nprocess_all_files()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:31:25.802731Z","iopub.execute_input":"2025-07-04T10:31:25.803079Z","iopub.status.idle":"2025-07-04T10:31:25.916130Z","shell.execute_reply.started":"2025-07-04T10:31:25.803052Z","shell.execute_reply":"2025-07-04T10:31:25.915533Z"}},"outputs":[{"name":"stdout","text":"üßπ Cleaning 33 files...\n‚úÖ Cleaned: 028_EMTER_F&F_2025_SK.pdf.txt\n‚úÖ Cleaned: 008_EMTER_F&F_2025_BG.pdf.txt\n‚úÖ Cleaned: 022_EMTER_F&F_2025_LV.pdf.txt\n‚úÖ Cleaned: 000_EMSA Catalogue 2025 v26.06.pdf.txt\n‚úÖ Cleaned: 031_European Maritime Transport Environmental Report 2025.pdf.txt\n‚úÖ Cleaned: 001_EMSA CAAR2024.pdf.txt\n‚úÖ Cleaned: 030_EMTER_F&F_2025_SV.pdf.txt\n‚úÖ Cleaned: 003_Seafarers Statistics in the EU 2023 data report.pdf.txt\n‚úÖ Cleaned: 024_EMTER_F&F_2025_NL.pdf.txt\n‚úÖ Cleaned: 023_EMTER_F&F_2025_MT.pdf.txt\n‚úÖ Cleaned: 018_EMTER_F&F_2025_HR.pdf.txt\n‚úÖ Cleaned: 011_EMTER_F&F_2025_DE.pdf.txt\n‚úÖ Cleaned: 005_ADER 2024.pdf.txt\n‚úÖ Cleaned: 004_AFVs Guidance 1.2 2025.pdf.txt\n‚úÖ Cleaned: 026_EMTER_F&F_2025_PT.pdf.txt\n‚úÖ Cleaned: 016_EMTER_F&F_2025_FR.pdf.txt\n‚úÖ Cleaned: 029_EMTER_F&F_2025_SL.pdf.txt\n‚úÖ Cleaned: 002_EMSA_FACTS_FIGURES_2024.pdf.txt\n‚úÖ Cleaned: 006_emsa ipa-enp newsletter issue 2.pdf.txt\n‚úÖ Cleaned: 025_EMTER_F&F_2025_PL.pdf.txt\n‚úÖ Cleaned: 020_EMTER_F&F_2025_IT.pdf.txt\n‚úÖ Cleaned: 014_EMTER_F&F_2025_ET.pdf.txt\n‚úÖ Cleaned: 012_EMTER_F&F_2025_EL.pdf.txt\n‚úÖ Cleaned: 019_EMTER_F&F_2025_HU.pdf.txt\n‚úÖ Cleaned: 013_EMTER_F&F_2025_ES.pdf.txt\n‚úÖ Cleaned: 010_EMTER_F&F_2025_DA.pdf.txt\n‚úÖ Cleaned: 017_EMTER_F&F_2025_GA.pdf.txt\n‚úÖ Cleaned: 021_EMTER_F&F_2025_LT.pdf.txt\n‚úÖ Cleaned: 015_EMTER_F&F_2025_FI.pdf.txt\n‚úÖ Cleaned: 007_EMTER_F&F_2025_EN.pdf.txt\n‚úÖ Cleaned: 032_EMSA Outlook 2025_v3.0.pdf.txt\n‚úÖ Cleaned: 009_EMTER_F&F_2025_CS.pdf.txt\n‚úÖ Cleaned: 027_EMTER_F&F_2025_RO.pdf.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# üö¢ 03_dataset_formatting.ipynb\n\nimport os\nimport json\nfrom pathlib import Path\n\n# üìÇ Input & Output Paths\nCLEANED_DIR = Path(\"data/emsa_cleaned\")\nOUTPUT_FILE = Path(\"data/emsa_dataset.jsonl\")\n\n# ‚öôÔ∏è Config\nSYSTEM_PROMPT = (\n    \"You are a maritime compliance assistant. \"\n    \"Answer questions based on maritime safety, regulatory, and operational documents. \"\n    \"Use precise and factual tone.\"\n)\n\ndef read_cleaned_files(directory):\n    \"\"\"\n    Load all cleaned text files and return as list of strings.\n    \"\"\"\n    files = sorted(directory.glob(\"*.txt\"))\n    docs = []\n\n    for f in files:\n        try:\n            text = f.read_text(encoding='utf-8').strip()\n            if len(text) < 100:\n                continue  # skip tiny fragments\n            docs.append({\n                \"filename\": f.name,\n                \"text\": text\n            })\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Skipping {f.name}: {e}\")\n\n    return docs\n\n\ndef convert_to_chat_format(text, filename):\n    \"\"\"\n    Wrap each document as a prompt-response chat pair (instruction-tuning style).\n    \"\"\"\n    return {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": f\"Summarize the key points of the following maritime document:\\n\\n{text[:2000]}\"},\n            {\"role\": \"assistant\", \"content\": f\"This is a regulatory excerpt from file '{filename}'. It includes technical maritime details. [PLACEHOLDER RESPONSE]\"}\n        ]\n    }\n\n# üì• Load cleaned docs\ndocuments = read_cleaned_files(CLEANED_DIR)\nprint(f\"üìÑ Loaded {len(documents)} documents.\")\n\n# üí¨ Format to chat-style dataset\nchat_data = [convert_to_chat_format(d[\"text\"], d[\"filename\"]) for d in documents]\n\n# üíæ Save to JSONL\nwith open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n    for item in chat_data:\n        json.dump(item, f, ensure_ascii=False)\n        f.write(\"\\n\")\n\nprint(f\"‚úÖ Saved JSONL dataset: {OUTPUT_FILE} ({len(chat_data)} samples)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:31:26.078678Z","iopub.execute_input":"2025-07-04T10:31:26.078936Z","iopub.status.idle":"2025-07-04T10:31:26.098625Z","shell.execute_reply.started":"2025-07-04T10:31:26.078912Z","shell.execute_reply":"2025-07-04T10:31:26.098042Z"}},"outputs":[{"name":"stdout","text":"üìÑ Loaded 1 documents.\n‚úÖ Saved JSONL dataset: data/emsa_dataset.jsonl (1 samples)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -q bitsandbytes accelerate peft transformers datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:31:26.099266Z","iopub.execute_input":"2025-07-04T10:31:26.099501Z","iopub.status.idle":"2025-07-04T10:32:48.024931Z","shell.execute_reply.started":"2025-07-04T10:31:26.099473Z","shell.execute_reply":"2025-07-04T10:32:48.024173Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#üß± 2. Load Dataset (from JSONL)\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"json\", data_files=\"data/emsa_dataset.jsonl\", split=\"train\")\nprint(f\"‚úÖ Loaded {len(dataset)} examples\")\n#üß± 3. Load Tokenizer & Apply Chat Template\nfrom transformers import AutoTokenizer\n\nMODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token  # avoid tokenizer errors\n\ndef apply_chat_template(example):\n    return {\"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)}\n\ndataset = dataset.map(apply_chat_template)\n#üß± 4. Tokenize Dataset\ndef tokenize(example):\n    tokens = tokenizer(\n        example[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_tensors=None  # important!\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # now copy() will work!\n    return tokens\n\n\ntokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names)\n#5. Load Model with LoRA\nimport torch\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n\nbnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\nmodel = prepare_model_for_kbit_training(model)\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n#üß± 6. Training Setup\n\nfrom transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n\ntraining_args = TrainingArguments(\n    output_dir=\"outputs/tinyllama-emsa\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    num_train_epochs=3,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    learning_rate=2e-4,\n    bf16=True if torch.cuda.is_available() else False,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n\n\ntrainer.train()\n\n\nmodel.save_pretrained(\"outputs/final_tinyllama_emsa\")\ntokenizer.save_pretrained(\"outputs/final_tinyllama_emsa\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:34:31.004642Z","iopub.execute_input":"2025-07-04T10:34:31.005332Z","iopub.status.idle":"2025-07-04T10:35:03.274344Z","shell.execute_reply.started":"2025-07-04T10:34:31.005309Z","shell.execute_reply":"2025-07-04T10:35:03.273566Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded 1 examples\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c87761f17be04c93a4a5ded9c1bad73f"}},"metadata":{}},{"name":"stderr","text":"2025-07-04 10:34:33.983205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751625274.197444      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751625274.259536      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c80cd53511f4ea0b1631440e64ade6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5741fef4a849e2974c81bd26718cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9224f42ab8124ce596a0df05494e46ea"}},"metadata":{}},{"name":"stdout","text":"trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/3778542792.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('outputs/final_tinyllama_emsa/tokenizer_config.json',\n 'outputs/final_tinyllama_emsa/special_tokens_map.json',\n 'outputs/final_tinyllama_emsa/tokenizer.model',\n 'outputs/final_tinyllama_emsa/added_tokens.json',\n 'outputs/final_tinyllama_emsa/tokenizer.json')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_path = \"outputs/final_tinyllama_emsa\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\nfrom datasets import load_dataset\n\neval_dataset = load_dataset(\"json\", data_files=\"data/emsa_dataset.jsonl\", split=\"train[:100%]\")  # adjust slice\neval_dataset = eval_dataset.map(lambda x: {\"text\": tokenizer.apply_chat_template(x[\"messages\"], tokenize=False)})\ndef tokenize_eval(example):\n    tokens = tokenizer(\n        example[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\ntokenized_eval = eval_dataset.map(tokenize_eval, remove_columns=eval_dataset.column_names)\nfrom transformers import Trainer, DataCollatorForLanguageModeling, TrainingArguments\n\neval_args = TrainingArguments(\n    output_dir=\"eval-outputs\",\n    per_device_eval_batch_size=2,\n    report_to=\"none\"\n)\n\neval_trainer = Trainer(\n    model=model,\n    args=eval_args,\n    eval_dataset=tokenized_eval,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\n\nresults = eval_trainer.evaluate()\nprint(\"üìä Evaluation Results:\", results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:39:09.283279Z","iopub.execute_input":"2025-07-04T10:39:09.284783Z","iopub.status.idle":"2025-07-04T10:39:11.659873Z","shell.execute_reply.started":"2025-07-04T10:39:09.284755Z","shell.execute_reply":"2025-07-04T10:39:11.659097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8993b4c2a75e42b9bc0dd60429f56587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd47802012ab48f2bf9f8677e87e7d78"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/1819326602.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"üìä Evaluation Results: {'eval_loss': 3.705432415008545, 'eval_model_preparation_time': 0.016, 'eval_runtime': 0.3492, 'eval_samples_per_second': 2.864, 'eval_steps_per_second': 2.864}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import math\nprint(\"üß† Perplexity:\", math.exp(results[\"eval_loss\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T10:40:09.496956Z","iopub.execute_input":"2025-07-04T10:40:09.497261Z","iopub.status.idle":"2025-07-04T10:40:09.501950Z","shell.execute_reply.started":"2025-07-04T10:40:09.497239Z","shell.execute_reply":"2025-07-04T10:40:09.501210Z"}},"outputs":[{"name":"stdout","text":"üß† Perplexity: 40.667628808413106\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}